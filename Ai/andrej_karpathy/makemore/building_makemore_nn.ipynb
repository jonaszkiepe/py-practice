{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b85bb6df-b289-4781-b906-0460bba689e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "words = open(\"names.txt\", \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "572d63b0-c365-4c70-92cf-8e66a03284ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# Create the training set of biagrams (x, y).\n",
    "xs, ys = [], []\n",
    "\n",
    "chars = sorted(set(\"\".join(words)))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "\n",
    "for w in words:\n",
    "    chs = [\".\"] + list(w) + [\".\"]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print(\"number of examples: \", num)\n",
    "# Randomly initialize 27 neurons' weights. each neuron receives 27 inputs.\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7466fed7-3b7b-4be9-b2e7-020003336453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4552338123321533\n",
      "2.4552323818206787\n",
      "2.455230951309204\n",
      "2.4552297592163086\n",
      "2.455228805541992\n",
      "2.4552271366119385\n",
      "2.455225944519043\n",
      "2.4552249908447266\n",
      "2.455223560333252\n",
      "2.4552223682403564\n",
      "2.455221176147461\n",
      "2.4552197456359863\n",
      "2.455218553543091\n",
      "2.4552173614501953\n",
      "2.4552161693573\n",
      "2.455214738845825\n",
      "2.455213785171509\n",
      "2.455212354660034\n",
      "2.4552109241485596\n",
      "2.455209493637085\n",
      "2.4552085399627686\n",
      "2.455207347869873\n",
      "2.4552063941955566\n",
      "2.455204963684082\n",
      "2.4552035331726074\n",
      "2.455202579498291\n",
      "2.4552013874053955\n",
      "2.4552001953125\n",
      "2.4551985263824463\n",
      "2.45519757270813\n",
      "2.4551963806152344\n",
      "2.455195188522339\n",
      "2.4551942348480225\n",
      "2.4551925659179688\n",
      "2.4551916122436523\n",
      "2.455190420150757\n",
      "2.4551889896392822\n",
      "2.455188274383545\n",
      "2.455186605453491\n",
      "2.455185651779175\n",
      "2.4551844596862793\n",
      "2.455183267593384\n",
      "2.4551823139190674\n",
      "2.4551808834075928\n",
      "2.455179452896118\n",
      "2.455178737640381\n",
      "2.4551773071289062\n",
      "2.4551761150360107\n",
      "2.4551751613616943\n",
      "2.455173969268799\n",
      "2.4551727771759033\n",
      "2.455171585083008\n",
      "2.4551703929901123\n",
      "2.455169439315796\n",
      "2.4551680088043213\n",
      "2.455167055130005\n",
      "2.4551658630371094\n",
      "2.455164670944214\n",
      "2.4551634788513184\n",
      "2.455162525177002\n",
      "2.4551613330841064\n",
      "2.45516037940979\n",
      "2.4551589488983154\n",
      "2.45515775680542\n",
      "2.4551568031311035\n",
      "2.455155611038208\n",
      "2.4551548957824707\n",
      "2.455153703689575\n",
      "2.4551520347595215\n",
      "2.455151081085205\n",
      "2.4551498889923096\n",
      "2.455148696899414\n",
      "2.4551477432250977\n",
      "2.455146551132202\n",
      "2.4551455974578857\n",
      "2.4551444053649902\n",
      "2.4551432132720947\n",
      "2.4551422595977783\n",
      "2.455141067504883\n",
      "2.4551401138305664\n",
      "2.455138921737671\n",
      "2.4551377296447754\n",
      "2.455136775970459\n",
      "2.4551355838775635\n",
      "2.455134630203247\n",
      "2.4551334381103516\n",
      "2.455132246017456\n",
      "2.4551312923431396\n",
      "2.455130100250244\n",
      "2.4551291465759277\n",
      "2.4551279544830322\n",
      "2.4551267623901367\n",
      "2.4551258087158203\n",
      "2.455124616622925\n",
      "2.4551236629486084\n",
      "2.455122470855713\n",
      "2.4551217555999756\n",
      "2.45512056350708\n",
      "2.4551193714141846\n",
      "2.455118179321289\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent\n",
    "for k in range(100):\n",
    "    # Forward Pass.\n",
    "    xenc = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = xenc @ W # log-counts\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    print(loss.item())\n",
    "    # Backward Pass.\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    # Update\n",
    "    W.data -= 50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "06ab5f34-7368-46e1-bbb1-a30f9fc91b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conakin.\n",
      "lalastan.\n",
      "tisonanisemyn.\n",
      "lewes.\n",
      "an.\n"
     ]
    }
   ],
   "source": [
    "# Sampling from the neural net\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = xenc @ W # log-counts\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "    \n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(\"\".join(out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
